# This starter workflow is for a CMake project running on a single platform. There is a different starter workflow if you need cross-platform coverage.
# See: https://github.com/actions/starter-workflows/blob/main/ci/cmake-multi-platform.yml
name: CMake on a single platform

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  # Customize the CMake build type here (Release, Debug, RelWithDebInfo, etc.)
  BUILD_TYPE: Release

jobs:
  build:
    # The CMake configure and build commands are platform agnostic and should work equally well on Windows or Mac.
    # You can convert this to a matrix build if you need cross-platform coverage.
    # See: https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/managing-complex-workflows#using-a-build-matrix
    runs-on: ubuntu-latest

    permissions:
      contents: read
      checks: write
      pull-requests: write

    steps:
    - uses: actions/checkout@v4

    - name: Configure CMake
      # Configure CMake in a 'build' subdirectory. `CMAKE_BUILD_TYPE` is only required if you are using a single-configuration generator such as make.
      # See https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html?highlight=cmake_build_type
      run: cmake -B ${{github.workspace}}/build -DCMAKE_BUILD_TYPE=${{env.BUILD_TYPE}}

    - name: Build
      # Build your program with the given configuration
      run: cmake --build ${{github.workspace}}/build --config ${{env.BUILD_TYPE}}

    - name: Test
      working-directory: ${{github.workspace}}/build
      # Execute tests defined by the CMake configuration.
      # See https://cmake.org/cmake/help/latest/manual/ctest.1.html for more detail
      run: ctest -C ${{env.BUILD_TYPE}} --output-on-failure --output-junit test_results.xml

    - name: Publish Test Results
      uses: EnricoMi/publish-unit-test-result-action@v2
      if: always()
      with:
        files: ${{github.workspace}}/build/test_results.xml
        check_name: Test Results

    - name: Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ github.sha }}
        path: ${{github.workspace}}/build/test_results.xml
        retention-days: 90

    - name: Run Benchmarks
      continue-on-error: true
      working-directory: ${{github.workspace}}/build
      run: ./challenge_1_benchmarks --benchmark_format=json --benchmark_out=benchmark_results.json

    - name: Debug tree
      run: tree -a

    - name: Publish Benchmark Results
      if: always()
      run: |
        if [ -f "${{github.workspace}}/build/benchmark_results.json" ]; then
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Benchmark | Time | CPU | Iterations |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|------|-----|------------|" >> $GITHUB_STEP_SUMMARY
          jq -r '.benchmarks[] | "| \(.name) | \(.real_time) \(.time_unit) | \(.cpu_time) \(.time_unit) | \(.iterations) |"' ${{github.workspace}}/build/benchmark_results.json >> $GITHUB_STEP_SUMMARY
        else
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ Benchmark results file not found. Benchmarks may have failed to run." >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload Benchmark Results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.sha }}
        path: ${{github.workspace}}/build/benchmark_results.json
        retention-days: 90
